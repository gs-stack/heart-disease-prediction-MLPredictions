{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "# The goal of this project is to predict the presence of heart disease in patients using the UCI Heart Disease dataset. \n",
    "# This is a supervised learning problem, specifically a binary classification task where the target variable indicates whether a patient has heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \n",
    "           \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
    "data = pd.read_csv(url, names=columns)\n",
    "\n",
    "# details of the dataset - columns and rows\n",
    "print(\"\\nNumber of rows and columns:\")\n",
    "print(data.shape)\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "The dataset contains 303 rows and 14 columns. The target variable (`target`) indicates the presence (1) or absence (0) of heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "# Replace '?' with NaN and drop missing values\n",
    "data.replace(\"?\", pd.NA, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convert columns to numeric\n",
    "data = data.astype(float)\n",
    "\n",
    "# Reclassify target to binary classification (0 for no disease, 1 for disease)\n",
    "data['target'] = (data['target'] > 0).astype(int)\n",
    "\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "## Visualize Data Distribution\n",
    "\n",
    "# Plot the distribution of the target variable\n",
    "sns.countplot(x=\"target\", data=data)\n",
    "plt.title(\"Heart Disease Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Correlation\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "# Boxplot for age and target\n",
    "sns.boxplot(x=\"target\", y=\"age\", data=data)\n",
    "plt.title(\"Age Distribution by Heart Disease Presence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Visualization\n",
    "# Pairplot for key features\n",
    "sns.pairplot(data, hue=\"target\", vars=[\"age\", \"chol\", \"thalach\", \"oldpeak\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the SVM model and model evaluation\n",
    "# Show cross-validation scores, classification report, and confusion matrix\n",
    "\n",
    "# Initialize and train the model\n",
    "svm = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(svm, X_train, y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ROC-AUC Score\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred)}\")\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for Validation Accuracy\n",
    "# Visualizes the accuracy of hyperparameter combinations for SVM (RBF kernel)\n",
    "\n",
    "def plot_heatmap(grid, param1, param2):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of validation accuracy from GridSearchCV.\n",
    "    \"\"\"\n",
    "    scores = grid.cv_results_[\"mean_test_score\"].reshape(len(grid.param_grid[param1]), len(grid.param_grid[param2]))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(scores, interpolation=\"nearest\", cmap=\"viridis\")\n",
    "    plt.xlabel(param2)\n",
    "    plt.ylabel(param1)\n",
    "    plt.colorbar(label=\"Validation Accuracy\")\n",
    "    plt.title(\"Validation Accuracy Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "# Grid search with validation heatmap\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "grid = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid.best_score_)\n",
    "\n",
    "# Plot heatmap\n",
    "plot_heatmap(grid, param1='C', param2='gamma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM with Hyperparameter Tuning\n",
    "# Shows the effect of the regularization parameter C on test accuracy with a plot\n",
    "\n",
    "def linear_svm_experiment(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Fit a linear SVM and evaluate with different values of C.\n",
    "    \"\"\"\n",
    "    C_values = [0.01, 0.1, 1, 10, 100]\n",
    "    results = []\n",
    "\n",
    "    for C in C_values:\n",
    "        lsvm = SVC(kernel='linear', C=C)\n",
    "        lsvm.fit(X_train, y_train)\n",
    "        score = lsvm.score(X_test, y_test)\n",
    "        results.append((C, score))\n",
    "        print(f\"C: {C}, Test Accuracy: {score:.4f}\")\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(C_values, [r[1] for r in results], marker='o')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('C (Regularization Parameter)')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.title('Effect of C on Test Accuracy (Linear SVM)')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "linear_svm_experiment(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning with GridSearchCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # Suppress UserWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)  # Suppress UndefinedMetricWarnings\n",
    "\n",
    "# Import this specific warning type from sklearn\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid.best_score_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Models - Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Multiple Models : The function compare_models iterates over the dictionary of models\n",
    "# Fits each model to the training set and evaluates it on the test set.\n",
    "# Computes metrics: Accuracy, Precision, Recall, F1-Score.\n",
    "# Displays the confusion matrix for each model.\n",
    "\n",
    "def compare_models(models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Compare multiple models and their performance metrics.\n",
    "\n",
    "    Args:\n",
    "        models (dict): A dictionary where keys are model names and values are the model instances.\n",
    "        X_train (ndarray): Training feature set.\n",
    "        y_train (ndarray): Training labels.\n",
    "        X_test (ndarray): Testing feature set.\n",
    "        y_test (ndarray): Testing labels.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe containing metrics for each model.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # Fit the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "        recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "        # Append the results\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-Score\": f1\n",
    "        })\n",
    "\n",
    "        # Print confusion matrix\n",
    "        print(f\"Confusion Matrix for {name}:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # Convert results to a dataframe\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "# Example Usage\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = {\n",
    "    \"SVM (Linear Kernel)\": SVC(kernel=\"linear\", C=1),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Compare the models\n",
    "results_df = compare_models(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n",
    "\n",
    "# Plot the comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "for metric in [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]:\n",
    "    plt.plot(results_df[\"Model\"], results_df[metric], marker=\"o\", label=metric)\n",
    "\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Scores\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Conclusion\n",
    "## Results and Discussion\n",
    "## Results and Conclusion\n",
    "\n",
    "### Results\n",
    "1. **Support Vector Machines (Linear Kernel):**\n",
    "   - Accuracy: **85.0%**\n",
    "   - Confusion Matrix:\n",
    "     ```\n",
    "     [[29  3]\n",
    "      [ 6 22]]\n",
    "     ```\n",
    "   - SVM performed well with balanced precision and recall, making it a strong candidate for this dataset.\n",
    "\n",
    "2. **Random Forest Classifier:**\n",
    "   - Accuracy: **85.0%**\n",
    "   - Confusion Matrix:\n",
    "     ```\n",
    "     [[29  3]\n",
    "      [ 6 22]]\n",
    "     ```\n",
    "   - The Random Forest model matched SVM in accuracy and showed robust performance due to its ability to handle feature interactions.\n",
    "\n",
    "3. **Logistic Regression:**\n",
    "   - Accuracy: **83.3%**\n",
    "   - Confusion Matrix:\n",
    "     ```\n",
    "     [[28  4]\n",
    "      [ 6 22]]\n",
    "     ```\n",
    "   - While slightly less accurate than SVM and Random Forest, Logistic Regression still provided competitive performance.\n",
    "\n",
    "   **Hyperparameter Tuning (SVM with RBF Kernel):**\n",
    "   - Best Parameters: `C = 10`, `gamma = 0.1`\n",
    "   - Best Cross-Validation Accuracy: **94.3%**\n",
    "   - Confusion Matrix on Test Data:\n",
    "     ```\n",
    "     [[32  0]\n",
    "      [28  0]]\n",
    "     ```\n",
    "   - The model struggled with class imbalance, as shown by its inability to correctly classify the minority class.\n",
    "\n",
    "5. **Ensemble Models:**\n",
    "   - An ensemble combining SVM, Random Forest, and Logistic Regression showed a slight improvement with an accuracy of **86%**. \n",
    "\n",
    "### Visualizations\n",
    "- Precision-recall curves and confusion matrices were used to evaluate the models' strengths and weaknesses.\n",
    "- Hyperparameter tuning results were visualized using heatmaps, which clearly highlighted the best parameter combinations for SVM.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "1. **Best Performing Model:**\n",
    "   - The **Support Vector Machine (Linear Kernel)** and **Random Forest** emerged as the best-performing models for this dataset, achieving high accuracy and balanced metrics.\n",
    "\n",
    "2. **Impact of Hyperparameter Tuning:**\n",
    "   - Tuning the SVM with an RBF kernel significantly improved cross-validation accuracy, showcasing the importance of parameter optimization. \n",
    "\n",
    "3. **Key Observations:**\n",
    "   - Models performed well in identifying patterns in the dataset \n",
    "   - Ensemble techniques offered a slight edge.\n",
    "\n",
    "The analysis and results demonstrate that machine learning models, particularly SVM and Random Forest, are effective tools for predicting heart disease. With further refinements, these models could be instrumental in building practical decision-support systems for healthcare applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
